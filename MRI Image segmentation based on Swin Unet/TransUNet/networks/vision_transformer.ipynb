{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vision_transformer.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNO2579keDPVHRSNJH+M6xd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# coding=utf-8\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import copy\n","import logging\n","import math\n","\n","from os.path import join as pjoin\n","\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","from torch.nn import CrossEntropyLoss, Dropout, Softmax, Linear, Conv2d, LayerNorm\n","from torch.nn.modules.utils import _pair\n","from scipy import ndimage\n","from .swin_transformer_unet_skip_expand_decoder_sys import SwinTransformerSys"],"metadata":{"id":"PQ9_XxMpTW2-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6. This is the model to be trained(SWINunet) which is created based on swin transformers or Hierarchical Vision Transformer using Shifted Windows.\n","\n"," this code takes the implementation of swin transformer, ceeates raw swinUnet and from a pretrained check point loads pretrained parameters for it\n","\n","\n","there are different arguments clearly defined in the code and the code is going to load pretrained model parametrs both for up sampling and downsampling layers"],"metadata":{"id":"i_vx3VQTHHhX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qniJQPVxTKqa"},"outputs":[],"source":["\n","\n","logger = logging.getLogger(__name__)\n","#this is the main class of network SwinUnet\n","class SwinUnet(nn.Module):\n","    def __init__(self, config, img_size=224, num_classes=21843, zero_head=False, vis=False):\n","        super(SwinUnet, self).__init__()\n","        self.num_classes = num_classes\n","        self.zero_head = zero_head\n","        self.config = config\n","        \n","        #swin unet is madeup Swin transformer with the following parameters as below\n","       r\"\"\" Swin Transformer\n","        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -\n","          https://arxiv.org/pdf/2103.14030\n","\n","    Args:\n","        img_size (int | tuple(int)): Input image size. Default 224\n","        patch_size (int | tuple(int)): Patch size. Default: 4\n","        in_chans (int): Number of input image channels. Default: 3\n","        num_classes (int): Number of classes for classification head. Default: 1000\n","        embed_dim (int): Patch embedding dimension. Default: 96\n","        depths (tuple(int)): Depth of each Swin Transformer layer.\n","        num_heads (tuple(int)): Number of attention heads in different layers.\n","        window_size (int): Window size. Default: 7\n","        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n","        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n","        qk_scale (float): Override default qk scale of head_dim ** -0.5 if set. Default: None\n","        drop_rate (float): Dropout rate. Default: 0\n","        attn_drop_rate (float): Attention dropout rate. Default: 0\n","        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n","        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n","        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False\n","        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n","        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n","    \"\"\"\n","        self.swin_unet = SwinTransformerSys(img_size=config.DATA.IMG_SIZE,\n","                                patch_size=config.MODEL.SWIN.PATCH_SIZE,\n","                                in_chans=config.MODEL.SWIN.IN_CHANS,\n","                                num_classes=self.num_classes,\n","                                embed_dim=config.MODEL.SWIN.EMBED_DIM,\n","                                depths=config.MODEL.SWIN.DEPTHS,\n","                                num_heads=config.MODEL.SWIN.NUM_HEADS,\n","                                window_size=config.MODEL.SWIN.WINDOW_SIZE,\n","                                mlp_ratio=config.MODEL.SWIN.MLP_RATIO,\n","                                qkv_bias=config.MODEL.SWIN.QKV_BIAS,\n","                                qk_scale=config.MODEL.SWIN.QK_SCALE,\n","                                drop_rate=config.MODEL.DROP_RATE,\n","                                drop_path_rate=config.MODEL.DROP_PATH_RATE,\n","                                ape=config.MODEL.SWIN.APE,\n","                                patch_norm=config.MODEL.SWIN.PATCH_NORM,\n","                                use_checkpoint=config.TRAIN.USE_CHECKPOINT)\n","    #it actually consists of different layers including encoder and decoder ,bottleneck ,etc, for more details check its code networks> swin_transormer.....\n","\n","    def forward(self, x):\n","        if x.size()[1] == 1:\n","            x = x.repeat(1,3,1,1)\n","        logits = self.swin_unet(x)\n","        return logits\n","\n","    def load_from(self, config):\n","        pretrained_path = config.MODEL.PRETRAIN_CKPT   #1.pretrained file name is specified in the cofiguration file\n","        if pretrained_path is not None:                  #2. \n","            print(\"pretrained_path:{}\".format(pretrained_path))\n","            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","            pretrained_dict = torch.load(pretrained_path, map_location=device) #3.loads the pretrained checkpoint\n","            \n","            if \"model\"  not in pretrained_dict:         \n","                print(\"---start load pretrained modle by splitting---\")\n","                pretrained_dict = {k[17:]:v for k,v in pretrained_dict.items()}\n","                for k in list(pretrained_dict.keys()):\n","                    if \"output\" in k:\n","                        print(\"delete key:{}\".format(k))\n","                        del pretrained_dict[k]\n","                msg = self.swin_unet.load_state_dict(pretrained_dict,strict=False)\n","                # print(msg)\n","                return\n","            pretrained_dict = pretrained_dict['model'] #take only key=model of pretrained check point\n","            print(\"---start load pretrained modle of swin encoder---\")  #4. start load pretrained modle of swin encoder---\n","            full_dict = copy.deepcopy(pretrained_dict)     #at this point full dict=pretrained dict=which includes parameters of pretrained model\n","\n","            #the goal of this for is updating the full dict \n","            for k, v in pretrained_dict.items(): # k in pretrained_dic is a pretrained parameter for different layer(mostly for layers). if this parameter (k)  \n","                                                  #is for a layer it starts with layer. then layer number     >  layer.0 for example \n","                if \"layers.\" in k:\n","                    current_layer_num = 3-int(k[7:8])   #int(k[7:8]) means x in  layer.x in k  > this is just a mapping > if layer.0 > current up_layer is 3\n","                                                                                                                           # layer.1 > current up_layer is 2\n","                                                                                                                           # layer.2 > current layer is 1\n","                                                                                                                          # this is done to coorectly load pretrained model based on implementation and simply can be said to be a renaming procedure\n","                    current_k = \"layers_up.\" + str(current_layer_num) + k[8:]  # reconstruct the name of k for update , to include parametrs for upsampling layers\n","                    full_dict.update({current_k:v})  # this is a full dict including parameters both for upsampling and downsampling pretrained model\n","\n","            \n","            model_dict = self.swin_unet.state_dict() #A state_dict is simply a Python dictionary object that maps each layer to its parameter tensor(learnable parameters)        \n","            for k in list(full_dict.keys()):\n","                if k in model_dict:\n","                    if full_dict[k].shape != model_dict[k].shape:\n","                        print(\"delete:{};shape pretrain:{};shape model:{}\".format(k,v.shape,model_dict[k].shape))\n","                        del full_dict[k]\n","\n","            msg = self.swin_unet.load_state_dict(full_dict, strict=False) #now we have a model parameters loaded from pretrained model  both for up and down sampling layers\n","            # print(msg)\n","        else:\n","            print(\"none pretrain\")"]}]}