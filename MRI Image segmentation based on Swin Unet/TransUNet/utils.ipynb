{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils.ipynb","provenance":[],"authorship_tag":"ABX9TyO7h+8KbRuuTS7E0G59Ym4E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import torch\n","from medpy import metric\n","from scipy.ndimage import zoom\n","import torch.nn as nn\n","import SimpleITK as sitk"],"metadata":{"id":"sZC89VBFbAgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DiceLoss(nn.Module):\n","    def __init__(self, n_classes):\n","        super(DiceLoss, self).__init__()\n","        self.n_classes = n_classes\n","\n","    def _one_hot_encoder(self, input_tensor):\n","        tensor_list = []\n","        for i in range(self.n_classes):\n","            temp_prob = input_tensor == i  # * torch.ones_like(input_tensor)\n","            tensor_list.append(temp_prob.unsqueeze(1))\n","        output_tensor = torch.cat(tensor_list, dim=1)\n","        return output_tensor.float()\n","\n","    def _dice_loss(self, score, target):\n","        target = target.float()\n","        smooth = 1e-5\n","        intersect = torch.sum(score * target)\n","        y_sum = torch.sum(target * target)\n","        z_sum = torch.sum(score * score)\n","        loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n","        loss = 1 - loss\n","        return loss\n","\n","    def forward(self, inputs, target, weight=None, softmax=False):\n","        if softmax:\n","            inputs = torch.softmax(inputs, dim=1)\n","        target = self._one_hot_encoder(target)\n","        if weight is None:\n","            weight = [1] * self.n_classes\n","        assert inputs.size() == target.size(), 'predict {} & target {} shape do not match'.format(inputs.size(), target.size())\n","        class_wise_dice = []\n","        loss = 0.0\n","        for i in range(0, self.n_classes):\n","            dice = self._dice_loss(inputs[:, i], target[:, i])\n","            class_wise_dice.append(1.0 - dice.item())\n","            loss += dice * weight[i]\n","        return loss / self.n_classes\n"],"metadata":{"id":"LIqzaSRybEIU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dPGpzu71a71B"},"outputs":[],"source":["\n","\n","\n","def calculate_metric_percase(pred, gt):\n","    pred[pred > 0] = 1\n","    gt[gt > 0] = 1\n","    if pred.sum() > 0 and gt.sum()>0:\n","        dice = metric.binary.dc(pred, gt)\n","        hd95 = metric.binary.hd95(pred, gt)\n","        return dice, hd95\n","    elif pred.sum() > 0 and gt.sum()==0:\n","        return 1, 0\n","    else:\n","        return 0, 0\n","\n","\n"]},{"cell_type":"code","source":["def test_single_volume(image, label, net, classes, patch_size=[256, 256], test_save_path=None, case=None, z_spacing=1):\n","   \n","    image, label = image.squeeze(0).cpu().detach().numpy(), label.squeeze(0).cpu().detach().numpy()\n","    if len(image.shape) == 3:\n","        prediction = np.zeros_like(label)\n","        for ind in range(image.shape[0]):\n","            slice = image[ind, :, :] # images are 3d. so each slice must be evaluated seperatly, for each slice do :\n","            x, y = slice.shape[0], slice.shape[1] #take x and y pixels\n","            if x != patch_size[0] or y != patch_size[1]:\n","                slice = zoom(slice, (patch_size[0] / x, patch_size[1] / y), order=3)  # previous using 0\n","            input = torch.from_numpy(slice).unsqueeze(0).unsqueeze(0).float().cuda()\n","           \n","            net.eval() # take model to evaluation mode\n","           \n","            with torch.no_grad():\n","                outputs = net(input) # predict the output\n","                \n","                out = torch.argmax(torch.softmax(outputs, dim=1), dim=1).squeeze(0)\n","                out = out.cpu().detach().numpy()\n","                if x != patch_size[0] or y != patch_size[1]:\n","                    pred = zoom(out, (x / patch_size[0], y / patch_size[1]), order=0)\n","                else:\n","                    pred = out\n","                prediction[ind] = pred\n","    else:\n","        input = torch.from_numpy(image).unsqueeze(0).unsqueeze(0).float().cuda()\n","           \n","        net.eval()\n","        with torch.no_grad():\n","            \n","            out = torch.argmax(torch.softmax(net(input), dim=1), dim=1).squeeze(0)\n","            prediction = out.cpu().detach().numpy()\n","            \n","    metric_list = []\n","    for i in range(1, classes):\n","        metric_list.append(calculate_metric_percase(prediction == i, label == i))   #compare prediction with the labels of classes \n","\n","    if test_save_path is not None:\n","        img_itk = sitk.GetImageFromArray(image.astype(np.float32))\n","        prd_itk = sitk.GetImageFromArray(prediction.astype(np.float32))\n","        lab_itk = sitk.GetImageFromArray(label.astype(np.float32))\n","        img_itk.SetSpacing((1, 1, z_spacing))\n","        prd_itk.SetSpacing((1, 1, z_spacing))\n","        lab_itk.SetSpacing((1, 1, z_spacing))\n","        sitk.WriteImage(prd_itk, test_save_path + '/'+case + \"_pred.nii.gz\")\n","        sitk.WriteImage(img_itk, test_save_path + '/'+ case + \"_img.nii.gz\")\n","        sitk.WriteImage(lab_itk, test_save_path + '/'+ case + \"_gt.nii.gz\")\n","    return metric_list"],"metadata":{"id":"Wz5YMNTDbIFV"},"execution_count":null,"outputs":[]}]}