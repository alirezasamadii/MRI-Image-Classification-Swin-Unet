{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"trainer.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMAx7CtW287hyDoKJhvp5EP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import argparse\n","import logging\n","import os\n","import random\n","import sys\n","import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tensorboardX import SummaryWriter\n","from torch.nn.modules.loss import CrossEntropyLoss\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from utils import DiceLoss\n","from torchvision import transforms\n","from utils import test_single_volume"],"metadata":{"id":"bAvi6L2KfYkY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["12. and here we do usual steps happening for training : taking model to training mode\n","\n","defining loss functions which here is a combination of loss functions are used:\n","\n"," sum of cross entropy and dice loss, \n","settting the optimmizer , \n","\n","setting number of epochs and \n","\n","finally training"],"metadata":{"id":"Ak62g3WRcdbY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"k3e0LGMPetpo"},"outputs":[],"source":["def trainer_synapse(args, model, snapshot_path):\n","    from datasets.dataset_synapse import Synapse_dataset, RandomGenerator     \n","\n","    #event logging codes\n","    logging.basicConfig(filename=snapshot_path + \"/log.txt\", level=logging.INFO,\n","                        format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n","    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n","    logging.info(str(args))\n","\n","    #retrieving required parameters from args \n","    base_lr = args.base_lr\n","    num_classes = args.num_classes\n","    batch_size = args.batch_size * args.n_gpu\n","    # max_iterations = args.max_iterations\n","\n","\n","    # create a dataset class called synapse_dataset giving following arguments : location > datasynapse/train_npz    list_of training elements and randomly rotate and \n","    #flip the images to add randomness to dataset\n","    db_train = Synapse_dataset(base_dir=args.root_path, list_dir=args.list_dir, split=\"train\",\n","                               transform=transforms.Compose([RandomGenerator(output_size=[args.img_size, args.img_size])])\n","                               )   \n","    print(\"The length of train set is: {}\".format(len(db_train)))\n","\n","    def worker_init_fn(worker_id):\n","        random.seed(args.seed + worker_id)\n","    #common method to load batches of data \n","    trainloader = DataLoader(db_train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True,\n","                             worker_init_fn=worker_init_fn)\n","    if args.n_gpu > 1:\n","        model = nn.DataParallel(model)\n","    #take model to training mode\n","    model.train()\n","    #define loss functions: we are going to use a combination of losses\n","    #first :\n","    ce_loss = CrossEntropyLoss()\n","    #The Dice coefficient, or Dice-SÃ¸rensen coefficient, is a common metric for pixel segmentation that can also be modified to act as a loss function:\n","    dice_loss = DiceLoss(num_classes)\n","    #define optimzer\n","    optimizer = optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=0.0001)\n","    writer = SummaryWriter(snapshot_path + '/log')\n","    iter_num = 0\n","    max_epoch = args.max_epochs\n","    max_iterations = args.max_epochs * len(trainloader)  # max_epoch = max_iterations // len(trainloader) + 1\n","    logging.info(\"{} iterations per epoch. {} max iterations \".format(len(trainloader), max_iterations))\n","    best_performance = 0.0\n","    iterator = tqdm(range(max_epoch), ncols=70)\n","    #start training and compute losses\n","    for epoch_num in iterator:\n","        for i_batch, sampled_batch in enumerate(trainloader):\n","            #from dataset which consists of image and its lable retrieve image and label seperatly\n","            image_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n","            image_batch, label_batch = image_batch.cuda(), label_batch.cuda()\n","            #and predict label of image based on model\n","            outputs = model(image_batch)\n","            #then compute loss\n","            loss_ce = ce_loss(outputs, label_batch[:].long())\n","            loss_dice = dice_loss(outputs, label_batch, softmax=True)\n","            loss = 0.4 * loss_ce + 0.6 * loss_dice\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            lr_ = base_lr * (1.0 - iter_num / max_iterations) ** 0.9\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] = lr_\n","\n","            iter_num = iter_num + 1\n","            writer.add_scalar('info/lr', lr_, iter_num)\n","            writer.add_scalar('info/total_loss', loss, iter_num)\n","            writer.add_scalar('info/loss_ce', loss_ce, iter_num)\n","\n","            logging.info('iteration %d : loss : %f, loss_ce: %f' % (iter_num, loss.item(), loss_ce.item()))\n","            #save predictions for some iterations\n","            if iter_num % 20 == 0:\n","                image = image_batch[1, 0:1, :, :]\n","                image = (image - image.min()) / (image.max() - image.min())\n","                writer.add_image('train/Image', image, iter_num)\n","                outputs = torch.argmax(torch.softmax(outputs, dim=1), dim=1, keepdim=True)\n","                writer.add_image('train/Prediction', outputs[1, ...] * 50, iter_num)\n","                labs = label_batch[1, ...].unsqueeze(0) * 50\n","                writer.add_image('train/GroundTruth', labs, iter_num)\n","        #save checkpoints\n","        save_interval = 50  # int(max_epoch/6)\n","        if epoch_num > int(max_epoch / 2) and (epoch_num + 1) % save_interval == 0:\n","            save_mode_path = os.path.join(snapshot_path, 'epoch_' + str(epoch_num) + '.pth')\n","            torch.save(model.state_dict(), save_mode_path)\n","            logging.info(\"save model to {}\".format(save_mode_path))\n","        # save final model\n","        if epoch_num >= max_epoch - 1:\n","            save_mode_path = os.path.join(snapshot_path, 'epoch_' + str(epoch_num) + '.pth')\n","            torch.save(model.state_dict(), save_mode_path)\n","            logging.info(\"save model to {}\".format(save_mode_path))\n","            iterator.close()\n","            break\n","\n","    writer.close()\n","    return \"Training Finished!\""]}]}